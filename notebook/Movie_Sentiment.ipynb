{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zav2RdAYAx3C"
      },
      "source": [
        "# Implementing RNN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "1K42jN5KAP0H"
      },
      "outputs": [],
      "source": [
        "# importing libraries\n",
        "import pandas as pd\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "EmCVhpliBCPX"
      },
      "outputs": [],
      "source": [
        "# This is the document we are going to tokenize\n",
        "docs = [\n",
        "    \"Life is full of unexpected surprises.\",\n",
        "    \"She enjoys reading books every evening.\",\n",
        "    \"Dreams come true.\",\n",
        "    \"Always stay positive and keep moving.\",\n",
        "    \"The stars shone brightly last night.\",\n",
        "    \"Never give up on your dreams.\",\n",
        "    \"They built a beautiful wooden house.\",\n",
        "    \"Learning something new expands your mind.\",\n",
        "    \"The cat jumped over the fence.\",\n",
        "    \"Hard work often leads to success.\"\n",
        "]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8-KzqT3RB0rh",
        "outputId": "01247dc4-537d-4e86-a7d9-05f914362221"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.11/dist-packages (2.17.1)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (25.1.21)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: h5py>=3.10.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.12.1)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: ml-dtypes<0.5.0,>=0.3.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.4.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from tensorflow) (24.2)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (4.25.5)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.32.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from tensorflow) (75.1.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.17.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.5.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (4.12.2)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.17.2)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.69.0)\n",
            "Requirement already satisfied: tensorboard<2.18,>=2.17 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.17.1)\n",
            "Requirement already satisfied: keras>=3.2.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.5.0)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.37.1)\n",
            "Requirement already satisfied: numpy<2.0.0,>=1.23.5 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.26.4)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from keras>=3.2.0->tensorflow) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.11/dist-packages (from keras>=3.2.0->tensorflow) (0.0.8)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.11/dist-packages (from keras>=3.2.0->tensorflow) (0.14.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (2024.12.14)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.18,>=2.17->tensorflow) (3.7)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.18,>=2.17->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.18,>=2.17->tensorflow) (3.1.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from werkzeug>=1.0.1->tensorboard<2.18,>=2.17->tensorflow) (3.0.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.2.0->tensorflow) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.2.0->tensorflow) (2.18.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.2.0->tensorflow) (0.1.2)\n"
          ]
        }
      ],
      "source": [
        "# Installing tensorflow\n",
        "!pip install tensorflow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "Ily-NLdJBaGc"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "tokenizer = Tokenizer(oov_token = \"<nothing>\") # (out of vocabulary) suppose while prediction, if users give a words which is not in vocabulary then it will use nothing instead"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "i8FtjouSESw5"
      },
      "outputs": [],
      "source": [
        "# Tokenize the vocabulary (converting uppercase inot lowercase)\n",
        "tokenizer.fit_on_texts(docs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9RGq4mY5BsLi",
        "outputId": "1ba22c7c-808d-4609-d5a1-45d3bd15da40"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'<nothing>': 1,\n",
              " 'the': 2,\n",
              " 'dreams': 3,\n",
              " 'your': 4,\n",
              " 'life': 5,\n",
              " 'is': 6,\n",
              " 'full': 7,\n",
              " 'of': 8,\n",
              " 'unexpected': 9,\n",
              " 'surprises': 10,\n",
              " 'she': 11,\n",
              " 'enjoys': 12,\n",
              " 'reading': 13,\n",
              " 'books': 14,\n",
              " 'every': 15,\n",
              " 'evening': 16,\n",
              " 'come': 17,\n",
              " 'true': 18,\n",
              " 'always': 19,\n",
              " 'stay': 20,\n",
              " 'positive': 21,\n",
              " 'and': 22,\n",
              " 'keep': 23,\n",
              " 'moving': 24,\n",
              " 'stars': 25,\n",
              " 'shone': 26,\n",
              " 'brightly': 27,\n",
              " 'last': 28,\n",
              " 'night': 29,\n",
              " 'never': 30,\n",
              " 'give': 31,\n",
              " 'up': 32,\n",
              " 'on': 33,\n",
              " 'they': 34,\n",
              " 'built': 35,\n",
              " 'a': 36,\n",
              " 'beautiful': 37,\n",
              " 'wooden': 38,\n",
              " 'house': 39,\n",
              " 'learning': 40,\n",
              " 'something': 41,\n",
              " 'new': 42,\n",
              " 'expands': 43,\n",
              " 'mind': 44,\n",
              " 'cat': 45,\n",
              " 'jumped': 46,\n",
              " 'over': 47,\n",
              " 'fence': 48,\n",
              " 'hard': 49,\n",
              " 'work': 50,\n",
              " 'often': 51,\n",
              " 'leads': 52,\n",
              " 'to': 53,\n",
              " 'success': 54}"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "# Alloated index value to vocabulary\n",
        "tokenizer.word_index"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JePlzHhKEi_J",
        "outputId": "499f50d0-5f95-4a86-d4cd-77a154dda7da"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "54"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "# Total number of vocabulary\n",
        "len(tokenizer.word_index)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NrbGpg9uE4x8",
        "outputId": "b1eac1b2-1658-4b40-a8bf-ca88872e9a98"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "10"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "#  Number of rows or number of document\n",
        "tokenizer.document_count"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p0av7crtHhcb",
        "outputId": "bc1e7570-7ed7-4be4-b0ee-23cb1acb0524"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[5, 6, 7, 8, 9, 10],\n",
              " [11, 12, 13, 14, 15, 16],\n",
              " [3, 17, 18],\n",
              " [19, 20, 21, 22, 23, 24],\n",
              " [2, 25, 26, 27, 28, 29],\n",
              " [30, 31, 32, 33, 4, 3],\n",
              " [34, 35, 36, 37, 38, 39],\n",
              " [40, 41, 42, 43, 4, 44],\n",
              " [2, 45, 46, 47, 2, 48],\n",
              " [49, 50, 51, 52, 53, 54]]"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "# Converting each sentence/document into a sequence of word indices based on the tokenizer's vocabulary\n",
        "sequences = tokenizer.texts_to_sequences(docs)\n",
        "sequences"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l6rY4qoLJA-y",
        "outputId": "8f1468c6-13d7-408a-9d1a-498452b90d58"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 5,  6,  7,  8,  9, 10,  0],\n",
              "       [11, 12, 13, 14, 15, 16,  0],\n",
              "       [ 3, 17, 18,  0,  0,  0,  0],\n",
              "       [19, 20, 21, 22, 23, 24,  0],\n",
              "       [ 2, 25, 26, 27, 28, 29,  0],\n",
              "       [30, 31, 32, 33,  4,  3,  0],\n",
              "       [34, 35, 36, 37, 38, 39,  0],\n",
              "       [40, 41, 42, 43,  4, 44,  0],\n",
              "       [ 2, 45, 46, 47,  2, 48,  0],\n",
              "       [49, 50, 51, 52, 53, 54,  0]], dtype=int32)"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "# applying padding to make each document into same size\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "padded_sequences = pad_sequences(sequences, padding = \"post\", maxlen = 7) # keeping sequnce length of each documment as 7\n",
        "padded_sequences"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dPJhE6Pxfccs"
      },
      "source": [
        "# Applying RNN on IMDB Datset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "vwvK0o19esSM"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.datasets import imdb\n",
        "from tensorflow.keras.models import Sequential, load_model\n",
        "from tensorflow.keras.layers import Dense, Embedding, SimpleRNN, Flatten\n",
        "from tensorflow.keras.callbacks import EarlyStopping"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "uLD7i1plgd1R"
      },
      "outputs": [],
      "source": [
        "(X_train, y_train), (X_test, y_test) = imdb.load_data(num_words=10000)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k9ryDHi1gn0C",
        "outputId": "6f98597c-ce8a-4192-ed45-fe41bf6cc097"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((25000,), (25000,), (25000,), (25000,))"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ],
      "source": [
        "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZWhaDPSOgqJj",
        "outputId": "0bb9dc40-5d1f-4a92-b006-50595a0ac0cd"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1,\n",
              " 14,\n",
              " 22,\n",
              " 16,\n",
              " 43,\n",
              " 530,\n",
              " 973,\n",
              " 1622,\n",
              " 1385,\n",
              " 65,\n",
              " 458,\n",
              " 4468,\n",
              " 66,\n",
              " 3941,\n",
              " 4,\n",
              " 173,\n",
              " 36,\n",
              " 256,\n",
              " 5,\n",
              " 25,\n",
              " 100,\n",
              " 43,\n",
              " 838,\n",
              " 112,\n",
              " 50,\n",
              " 670,\n",
              " 2,\n",
              " 9,\n",
              " 35,\n",
              " 480,\n",
              " 284,\n",
              " 5,\n",
              " 150,\n",
              " 4,\n",
              " 172,\n",
              " 112,\n",
              " 167,\n",
              " 2,\n",
              " 336,\n",
              " 385,\n",
              " 39,\n",
              " 4,\n",
              " 172,\n",
              " 4536,\n",
              " 1111,\n",
              " 17,\n",
              " 546,\n",
              " 38,\n",
              " 13,\n",
              " 447,\n",
              " 4,\n",
              " 192,\n",
              " 50,\n",
              " 16,\n",
              " 6,\n",
              " 147,\n",
              " 2025,\n",
              " 19,\n",
              " 14,\n",
              " 22,\n",
              " 4,\n",
              " 1920,\n",
              " 4613,\n",
              " 469,\n",
              " 4,\n",
              " 22,\n",
              " 71,\n",
              " 87,\n",
              " 12,\n",
              " 16,\n",
              " 43,\n",
              " 530,\n",
              " 38,\n",
              " 76,\n",
              " 15,\n",
              " 13,\n",
              " 1247,\n",
              " 4,\n",
              " 22,\n",
              " 17,\n",
              " 515,\n",
              " 17,\n",
              " 12,\n",
              " 16,\n",
              " 626,\n",
              " 18,\n",
              " 2,\n",
              " 5,\n",
              " 62,\n",
              " 386,\n",
              " 12,\n",
              " 8,\n",
              " 316,\n",
              " 8,\n",
              " 106,\n",
              " 5,\n",
              " 4,\n",
              " 2223,\n",
              " 5244,\n",
              " 16,\n",
              " 480,\n",
              " 66,\n",
              " 3785,\n",
              " 33,\n",
              " 4,\n",
              " 130,\n",
              " 12,\n",
              " 16,\n",
              " 38,\n",
              " 619,\n",
              " 5,\n",
              " 25,\n",
              " 124,\n",
              " 51,\n",
              " 36,\n",
              " 135,\n",
              " 48,\n",
              " 25,\n",
              " 1415,\n",
              " 33,\n",
              " 6,\n",
              " 22,\n",
              " 12,\n",
              " 215,\n",
              " 28,\n",
              " 77,\n",
              " 52,\n",
              " 5,\n",
              " 14,\n",
              " 407,\n",
              " 16,\n",
              " 82,\n",
              " 2,\n",
              " 8,\n",
              " 4,\n",
              " 107,\n",
              " 117,\n",
              " 5952,\n",
              " 15,\n",
              " 256,\n",
              " 4,\n",
              " 2,\n",
              " 7,\n",
              " 3766,\n",
              " 5,\n",
              " 723,\n",
              " 36,\n",
              " 71,\n",
              " 43,\n",
              " 530,\n",
              " 476,\n",
              " 26,\n",
              " 400,\n",
              " 317,\n",
              " 46,\n",
              " 7,\n",
              " 4,\n",
              " 2,\n",
              " 1029,\n",
              " 13,\n",
              " 104,\n",
              " 88,\n",
              " 4,\n",
              " 381,\n",
              " 15,\n",
              " 297,\n",
              " 98,\n",
              " 32,\n",
              " 2071,\n",
              " 56,\n",
              " 26,\n",
              " 141,\n",
              " 6,\n",
              " 194,\n",
              " 7486,\n",
              " 18,\n",
              " 4,\n",
              " 226,\n",
              " 22,\n",
              " 21,\n",
              " 134,\n",
              " 476,\n",
              " 26,\n",
              " 480,\n",
              " 5,\n",
              " 144,\n",
              " 30,\n",
              " 5535,\n",
              " 18,\n",
              " 51,\n",
              " 36,\n",
              " 28,\n",
              " 224,\n",
              " 92,\n",
              " 25,\n",
              " 104,\n",
              " 4,\n",
              " 226,\n",
              " 65,\n",
              " 16,\n",
              " 38,\n",
              " 1334,\n",
              " 88,\n",
              " 12,\n",
              " 16,\n",
              " 283,\n",
              " 5,\n",
              " 16,\n",
              " 4472,\n",
              " 113,\n",
              " 103,\n",
              " 32,\n",
              " 15,\n",
              " 16,\n",
              " 5345,\n",
              " 19,\n",
              " 178,\n",
              " 32]"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ],
      "source": [
        "X_train[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ygidrU_SjicB"
      },
      "source": [
        "#### All the data is already tokenized"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SMHmaMoJhCij",
        "outputId": "826f3d76-b10d-441b-8f4f-86ef58ce4225"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 0, 0, ..., 0, 1, 0])"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ],
      "source": [
        "y_train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C3YEjNiuhwsk",
        "outputId": "fca2c1b8-3f9c-47e2-e467-5a937caf9970"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The length of longest document is 2494\n"
          ]
        }
      ],
      "source": [
        "# checking the longest document\n",
        "a = 0\n",
        "for i in X_train:\n",
        "    if len(i) > a:\n",
        "        a = len(i)\n",
        "print(f\"The length of longest document is {a}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cRiJfgZtii72",
        "outputId": "c300be95-a1d5-4362-f9d9-414354e48b97"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The length of longest document is 2315\n"
          ]
        }
      ],
      "source": [
        "# checking the longest document\n",
        "a = 0\n",
        "for i in X_test:\n",
        "    if len(i) > a:\n",
        "        a = len(i)\n",
        "print(f\"The length of longest document is {a}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5Ol5dYwKiowS"
      },
      "source": [
        "#### As we can see the longest document length in X_train and Y_train is 2494, so i will be keeping padding(maxlen) as 2500"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "7owhDquchkfD"
      },
      "outputs": [],
      "source": [
        "# we will apply padding on each document to convert it into same length\n",
        "X_train_padded = pad_sequences(X_train, padding = \"post\", maxlen = 100)\n",
        "X_test_padded = pad_sequences(X_test, padding = \"post\", maxlen = 100)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iQ_fgBNUjDnr",
        "outputId": "8c267466-12e0-444a-b2b8-6b06a0587dde"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(25000, 100)\n",
            "--------------------------------------------------\n",
            "100\n",
            "--------------------------------------------------\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1415,   33,    6, ...,   19,  178,   32],\n",
              "       [ 163,   11, 3215, ...,   16,  145,   95],\n",
              "       [1301,    4, 1873, ...,    7,  129,  113],\n",
              "       ...,\n",
              "       [  11,    6, 4065, ...,    4, 3586,    2],\n",
              "       [ 100, 2198,    8, ...,   12,    9,   23],\n",
              "       [  78, 1099,   17, ...,  204,  131,    9]], dtype=int32)"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ],
      "source": [
        "print(X_train_padded.shape)\n",
        "print(50*\"-\")\n",
        "print(len(X_train_padded[0]))\n",
        "print(50*\"-\")\n",
        "X_train_padded"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8dXVvvwRjr-x"
      },
      "source": [
        "#### we will apply embedding on each token in the document with some specific dimension\n",
        "- input_dim=10000: The size of the vocabulary. In this case, we're using a vocabulary of 10,000 unique tokens (words).\n",
        "- output_dim=64: The size of the embedding vectors. Each word will be represented by a 64-dimensional vector.\n",
        "- input_length=100: The length of each input sequence. In this case, each input sequence will be 100 tokens long (e.g., 500 words in a sentence or document)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "U81ru4xljFru",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1d0bddcd-3940-4e17-d049-7dfbc441d668"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "# creating layers for model\n",
        "model = Sequential()\n",
        "model.add(Embedding(input_dim = 10000, output_dim =64, input_length = 100))\n",
        "model.add(SimpleRNN(units= 128, activation=\"relu\"))\n",
        "model.add(Dense(1, activation=\"sigmoid\"))\n",
        "\n",
        "# Build the model explicitly\n",
        "model.build(input_shape=(None, 100))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 242
        },
        "id": "VxBknfZNmJW4",
        "outputId": "e84793fb-5988-4616-ea8e-9c834e5f7151"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_1\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ embedding_1 (\u001b[38;5;33mEmbedding\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │         \u001b[38;5;34m640,000\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ simple_rnn_1 (\u001b[38;5;33mSimpleRNN\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │          \u001b[38;5;34m24,704\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)                   │             \u001b[38;5;34m129\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ embedding_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">640,000</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ simple_rnn_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">SimpleRNN</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │          <span style=\"color: #00af00; text-decoration-color: #00af00\">24,704</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                   │             <span style=\"color: #00af00; text-decoration-color: #00af00\">129</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m664,833\u001b[0m (2.54 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">664,833</span> (2.54 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m664,833\u001b[0m (2.54 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">664,833</span> (2.54 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PSSUgAAKoq1v",
        "outputId": "76c6e8c9-aa74-44b3-dd6e-65c960768ed9"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.early_stopping.EarlyStopping at 0x7ad916219d10>"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ],
      "source": [
        "# creating an instance of early stopping\n",
        "earlyStopping = EarlyStopping(monitor= \"val_loss\", patience = 5, restore_best_weights = True)\n",
        "earlyStopping"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "0AIk0WU8pd6m"
      },
      "outputs": [],
      "source": [
        "# compile the model\n",
        "model.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=[\"accuracy\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HKcNj8xcpZed",
        "outputId": "efec894e-bb96-4189-9a56-47eb376a9ef5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 44ms/step - accuracy: 0.5727 - loss: 0.6971 - val_accuracy: 0.6614 - val_loss: 0.5968\n",
            "Epoch 2/100\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 44ms/step - accuracy: 0.7000 - loss: 0.6661 - val_accuracy: 0.6618 - val_loss: 0.5859\n",
            "Epoch 3/100\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 44ms/step - accuracy: 0.7660 - loss: 0.4881 - val_accuracy: 0.7184 - val_loss: 0.5389\n",
            "Epoch 4/100\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 44ms/step - accuracy: 0.8008 - loss: 0.4314 - val_accuracy: 0.7062 - val_loss: 0.5835\n",
            "Epoch 5/100\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 44ms/step - accuracy: 0.7768 - loss: 0.4520 - val_accuracy: 0.6714 - val_loss: 0.6172\n",
            "Epoch 6/100\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 44ms/step - accuracy: 0.8315 - loss: 0.3630 - val_accuracy: 0.7676 - val_loss: 0.5546\n",
            "Epoch 7/100\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 44ms/step - accuracy: 0.8883 - loss: 0.2763 - val_accuracy: 0.6694 - val_loss: 0.6754\n",
            "Epoch 8/100\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 45ms/step - accuracy: 0.8756 - loss: 0.2904 - val_accuracy: 0.7820 - val_loss: 0.6075\n"
          ]
        }
      ],
      "source": [
        "# Train the model\n",
        "history = model.fit(X_train_padded, y_train, epochs=100,validation_split=0.2, callbacks=[earlyStopping])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "bo2H2t-7psSK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "32272989-2fd3-46b3-c21a-c6d7f1f93ba9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 11ms/step - accuracy: 0.7188 - loss: 0.5496\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.5442382097244263, 0.7218000292778015]"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ],
      "source": [
        "model.evaluate(X_test_padded, y_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We got an accuracy of 72 percent"
      ],
      "metadata": {
        "id": "w7MVG-bQlRCY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Testing the model with some data"
      ],
      "metadata": {
        "id": "EofSe_sylp7K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data = \"This is the best movie I’ve ever seen absolutely perfect in every way! and very good\""
      ],
      "metadata": {
        "id": "JFhZ_wiak419"
      },
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "token = Tokenizer()\n",
        "token.fit_on_texts([data])"
      ],
      "metadata": {
        "id": "7a7Ho007mvWR"
      },
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "token.word_index"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JeDCtbQ5mzWF",
        "outputId": "9df622ff-46d4-4c6f-d268-77241da4b9e8"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'this': 1,\n",
              " 'is': 2,\n",
              " 'the': 3,\n",
              " 'best': 4,\n",
              " 'movie': 5,\n",
              " 'i’ve': 6,\n",
              " 'ever': 7,\n",
              " 'seen': 8,\n",
              " 'absolutely': 9,\n",
              " 'perfect': 10,\n",
              " 'in': 11,\n",
              " 'every': 12,\n",
              " 'way': 13,\n",
              " 'and': 14,\n",
              " 'very': 15,\n",
              " 'good': 16}"
            ]
          },
          "metadata": {},
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sequence1 = token.texts_to_sequences([data])\n",
        "sequence1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wxJK-HavnGod",
        "outputId": "6b911516-0060-4dba-a566-b761ca2daaab"
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16]]"
            ]
          },
          "metadata": {},
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "padded_sequence = pad_sequences(sequence1, padding='post', maxlen=100) #Example maxlen\n",
        "padded_sequence"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ix4vPQLynSGg",
        "outputId": "789411d6-7ed0-46ab-84f0-64e249f4e1bf"
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,\n",
              "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
              "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
              "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
              "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
              "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
              "         0,  0,  0,  0]], dtype=int32)"
            ]
          },
          "metadata": {},
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "aa = model.predict(padded_sequence)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iPubGl3hmAMn",
        "outputId": "fc31defd-ba8f-48c7-8693-35785c82047b"
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "aa[0][0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GAJtAY9QnffN",
        "outputId": "99e7f17e-44c0-47e7-83cf-9347c5893fba"
      },
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.6643697"
            ]
          },
          "metadata": {},
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "OfTM-zfwx576"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}