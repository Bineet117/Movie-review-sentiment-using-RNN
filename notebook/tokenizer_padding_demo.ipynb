{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementing Tokenizer and padding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing libraries\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Installing tensorflow\n",
    "!pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the document we are going to tokenize\n",
    "docs = [\n",
    "    \"Life is full of unexpected surprises.\",\n",
    "    \"She enjoys reading books every evening.\",\n",
    "    \"Dreams come true.\",\n",
    "    \"Always stay positive and keep moving.\",\n",
    "    \"The stars shone brightly last night.\",\n",
    "    \"Never give up on your dreams.\",\n",
    "    \"They built a beautiful wooden house.\",\n",
    "    \"Learning something new expands your mind.\",\n",
    "    \"The cat jumped over the fence.\",\n",
    "    \"Hard work often leads to success.\"\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "tokenizer = Tokenizer(oov_token = \"<nothing>\") # (out of vocabulary) suppose while prediction, if users give a words which is not in vocabulary then it will use nothing instead"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize the vocabulary (converting uppercase inot lowercase)\n",
    "tokenizer.fit_on_texts(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'<nothing>': 1,\n",
       " 'the': 2,\n",
       " 'dreams': 3,\n",
       " 'your': 4,\n",
       " 'life': 5,\n",
       " 'is': 6,\n",
       " 'full': 7,\n",
       " 'of': 8,\n",
       " 'unexpected': 9,\n",
       " 'surprises': 10,\n",
       " 'she': 11,\n",
       " 'enjoys': 12,\n",
       " 'reading': 13,\n",
       " 'books': 14,\n",
       " 'every': 15,\n",
       " 'evening': 16,\n",
       " 'come': 17,\n",
       " 'true': 18,\n",
       " 'always': 19,\n",
       " 'stay': 20,\n",
       " 'positive': 21,\n",
       " 'and': 22,\n",
       " 'keep': 23,\n",
       " 'moving': 24,\n",
       " 'stars': 25,\n",
       " 'shone': 26,\n",
       " 'brightly': 27,\n",
       " 'last': 28,\n",
       " 'night': 29,\n",
       " 'never': 30,\n",
       " 'give': 31,\n",
       " 'up': 32,\n",
       " 'on': 33,\n",
       " 'they': 34,\n",
       " 'built': 35,\n",
       " 'a': 36,\n",
       " 'beautiful': 37,\n",
       " 'wooden': 38,\n",
       " 'house': 39,\n",
       " 'learning': 40,\n",
       " 'something': 41,\n",
       " 'new': 42,\n",
       " 'expands': 43,\n",
       " 'mind': 44,\n",
       " 'cat': 45,\n",
       " 'jumped': 46,\n",
       " 'over': 47,\n",
       " 'fence': 48,\n",
       " 'hard': 49,\n",
       " 'work': 50,\n",
       " 'often': 51,\n",
       " 'leads': 52,\n",
       " 'to': 53,\n",
       " 'success': 54}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Alloated index value to vocabulary\n",
    "tokenizer.word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "54"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Total number of vocabulary\n",
    "len(tokenizer.word_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Number of rows or number of document\n",
    "tokenizer.document_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[5, 6, 7, 8, 9, 10],\n",
       " [11, 12, 13, 14, 15, 16],\n",
       " [3, 17, 18],\n",
       " [19, 20, 21, 22, 23, 24],\n",
       " [2, 25, 26, 27, 28, 29],\n",
       " [30, 31, 32, 33, 4, 3],\n",
       " [34, 35, 36, 37, 38, 39],\n",
       " [40, 41, 42, 43, 4, 44],\n",
       " [2, 45, 46, 47, 2, 48],\n",
       " [49, 50, 51, 52, 53, 54]]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Converting each sentence/document into a sequence of word indices based on the tokenizer's vocabulary\n",
    "sequences = tokenizer.texts_to_sequences(docs)\n",
    "sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 5,  6,  7,  8,  9, 10,  0],\n",
       "       [11, 12, 13, 14, 15, 16,  0],\n",
       "       [ 3, 17, 18,  0,  0,  0,  0],\n",
       "       [19, 20, 21, 22, 23, 24,  0],\n",
       "       [ 2, 25, 26, 27, 28, 29,  0],\n",
       "       [30, 31, 32, 33,  4,  3,  0],\n",
       "       [34, 35, 36, 37, 38, 39,  0],\n",
       "       [40, 41, 42, 43,  4, 44,  0],\n",
       "       [ 2, 45, 46, 47,  2, 48,  0],\n",
       "       [49, 50, 51, 52, 53, 54,  0]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# applying padding to make each document into same size\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "padded_sequences = pad_sequences(sequences, padding = \"post\", maxlen = 7) # keeping sequnce length of each documment as 7\n",
    "padded_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "a = pd.read_csv(r\"C:\\Users\\91620\\Desktop\\Movie-review-sentiment-using-RNN\\IMDB Dataset.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>One of the other reviewers has mentioned that ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I thought this was a wonderful way to spend ti...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Basically there's a family where a little boy ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review sentiment\n",
       "0  One of the other reviewers has mentioned that ...  positive\n",
       "1  A wonderful little production. <br /><br />The...  positive\n",
       "2  I thought this was a wonderful way to spend ti...  positive\n",
       "3  Basically there's a family where a little boy ...  negative\n",
       "4  Petter Mattei's \"Love in the Time of Money\" is...  positive"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 2)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word Index: {'movie': 1, 'this': 2, 'i': 3, 'was': 4, 'the': 5, 'loved': 6, 'awful': 7, 'enjoyed': 8, 'plot': 9, 'of': 10, 'it': 11, 'a': 12, 'bad': 13, 'is': 14, 'best': 15, 'ever': 16}\n",
      "\n",
      "Tokenized Reviews:\n",
      "Review 1: [2, 1]\n",
      "Review 2: [2, 1]\n",
      "Review 3: [2, 1]\n",
      "Review 4: [1]\n",
      "Review 5: [2, 1]\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "\n",
    "# from keras.preprocessing.text import Tokenizer\n",
    "\n",
    "# Sample data (list of reviews with words outside top 3 frequent words)\n",
    "reviews = [\n",
    "    \"I loved this movie\",   # \"loved\" is not in top 3\n",
    "    \"This movie was awful\", # \"was\" and \"awful\" are not in top 3\n",
    "    \"I enjoyed the plot of this movie\", # \"enjoyed\", \"plot\", \"of\" are not in top 3\n",
    "    \"It was a bad movie\",   # \"was\", \"a\", \"bad\" are not in top 3\n",
    "    \"This is the best movie ever!\"  # \"is\", \"best\", \"ever\" are not in top 3\n",
    "]\n",
    "\n",
    "# Create a Tokenizer with a limited vocabulary size (e.g., top 3 words)\n",
    "tokenizer = Tokenizer(num_words=3)\n",
    "tokenizer.fit_on_texts(reviews)\n",
    "\n",
    "# Print the word index (words mapped to integers)\n",
    "print(\"Word Index:\", tokenizer.word_index)\n",
    "\n",
    "# Convert text to sequences (replace words with their integer representations)\n",
    "sequences = tokenizer.texts_to_sequences(reviews)\n",
    "\n",
    "# Print the sequences (tokenized reviews)\n",
    "print(\"\\nTokenized Reviews:\")\n",
    "for i, seq in enumerate(sequences):\n",
    "    print(f\"Review {i+1}: {seq}\")\n",
    "# ns out of the top 3 words replaced by 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
